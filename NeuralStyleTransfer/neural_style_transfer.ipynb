{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_style_transfer",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZoAEw25JfFq"
      },
      "source": [
        "# Neural style transfer\n",
        "\n",
        "**Original Author:** [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2016/01/11<br>\n",
        "**Last modified:** 2020/05/02<br>\n",
        "**Description:** Transfering the style of a reference image to target image using gradient descent.<br><br>\n",
        "**This version maintained by:** [PrabeshRajJoshi](https://github.com/PrabeshRajJoshi)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywPmBCXEJfFr"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Style transfer consists in generating an image\n",
        "with the same \"content\" as a base image, but with the\n",
        "\"style\" of a different picture (typically artistic).\n",
        "This is achieved through the optimization of a loss function\n",
        "that has 3 components: \"style loss\", \"content loss\",\n",
        "and \"total variation loss\":\n",
        "\n",
        "- The total variation loss imposes local spatial continuity between\n",
        "the pixels of the combination image, giving it visual coherence.\n",
        "- The style loss is where the deep learning keeps in --that one is defined\n",
        "using a deep convolutional neural network. Precisely, it consists in a sum of\n",
        "L2 distances between the Gram matrices of the representations of\n",
        "the base image and the style reference image, extracted from\n",
        "different layers of a convnet (trained on ImageNet). The general idea\n",
        "is to capture color/texture information at different spatial\n",
        "scales (fairly large scales --defined by the depth of the layer considered).\n",
        "- The content loss is a L2 distance between the features of the base\n",
        "image (extracted from a deep layer) and the features of the combination image,\n",
        "keeping the generated image close enough to the original one.\n",
        "\n",
        "**Reference:** [A Neural Algorithm of Artistic Style](\n",
        "  http://arxiv.org/abs/1508.06576)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm2k-kp0JfFs"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_O2FCj_JfFs"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import vgg19\n",
        "\n",
        "# to support usage of local modules/images, https://colab.research.google.com/notebooks/io.ipynb#scrollTo=c2W5A2px3doP\n",
        "MOUNTPATH = \"/content/drive\"\n",
        "COLABPATH = MOUNTPATH + \"/My Drive/ColabNotebooks\"\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount( MOUNTPATH )\n",
        "sys.path.append( COLABPATH )\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%aimport image_tools\n",
        "from image_tools import get_drive_images, get_test_images, set_gen_img_dims\n",
        "from image_tools import preprocess_image, deprocess_image\n",
        "from image_tools import gram_matrix, style_loss, content_loss, total_variation_loss, StyleTransferLoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xlv8lw9hZLC5"
      },
      "source": [
        "### Set path to image files and prepare generated image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ccmd5iT4ZFAl"
      },
      "source": [
        "# get image files from google drive\n",
        "base_image_path, style_reference_image_path, result_prefix = get_drive_images(COLABPATH)\n",
        "\n",
        "'''\n",
        "# get test image files via download\n",
        "base_image_path, style_reference_image_path, result_prefix = get_test_images()\n",
        "'''\n",
        "\n",
        "# Dimensions of the generated picture.\n",
        "img_nrows, img_ncols = set_gen_img_dims(base_image_path=base_image_path, nrows=256)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7aSH_LXJfF1"
      },
      "source": [
        "## Check the base (content) image and the style reference image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Lx_COEJfF2"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(base_image_path))\n",
        "display(Image(style_reference_image_path))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eeqKP8zJfGB"
      },
      "source": [
        "## Compute the content, and style-transfer loss\n",
        "\n",
        "### First, define 4 utility functions in `image_tools` module:\n",
        "\n",
        "- `gram_matrix` (used to compute the style loss)\n",
        "- The `style_loss` function, which keeps the generated image close to the local textures\n",
        "of the style reference image\n",
        "- The `content_loss` function, which keeps the high-level representation of the\n",
        "generated image close to that of the base image\n",
        "- The `total_variation_loss` function, a regularization loss which keeps the generated\n",
        "image locally-coherent\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kw7S_OiJfGH"
      },
      "source": [
        "\n",
        "### Next, define a `StyleTransferLoss` class in the `image_tools` module:\n",
        "- it prepares a VGG19 model loaded with pre-trained ImageNet weights\n",
        "- it extracts the model features (such as layer names and layer outputs)\n",
        "- it assigns the layers to use for content loss and style loss\n",
        "- it assigns the weights for content loss and style loss\n",
        "- finally, it computes the style transfer loss using the 4 utility functions defined above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgV12DW1wJMi"
      },
      "source": [
        "# create an instance of the StyleTransferLoss class\n",
        "GokuPiccoloLoss = StyleTransferLoss()\n",
        "# setup the VGG19 model and extract features\n",
        "GokuPiccoloLoss.setup_feature_extractor()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqE9XEsVJfGX"
      },
      "source": [
        "## The training loop\n",
        "\n",
        "Repeatedly run vanilla gradient descent steps to minimize the loss, and save the\n",
        "resulting image every 100 iterations.\n",
        "\n",
        "We decay the learning rate by 0.96 every 100 steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aThMGo2fJfGX"
      },
      "source": [
        "optimizer = keras.optimizers.SGD(\n",
        "    keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate=100.0, decay_steps=100, decay_rate=0.96\n",
        "    )\n",
        ")\n",
        "\n",
        "base_image = preprocess_image(base_image_path, nrows=img_nrows, ncols=img_ncols)\n",
        "style_reference_image = preprocess_image(style_reference_image_path, nrows=img_nrows, ncols=img_ncols)\n",
        "combination_image = tf.Variable(preprocess_image(base_image_path, nrows=img_nrows, ncols=img_ncols))\n",
        "\n",
        "iterations = 4000\n",
        "for i in range(1, iterations + 1):\n",
        "    # use the method with tf.function decorator to calculate loss and gradients\n",
        "    loss, grads = GokuPiccoloLoss.compute_loss_and_grads(base_image=base_image,\n",
        "                                                         style_image=style_reference_image,\n",
        "                                                         combination_image=combination_image)\n",
        "    optimizer.apply_gradients([(grads, combination_image)])\n",
        "    if i % 2 == 0:\n",
        "        print(\"Iteration %d: loss=%.2f\" % (i, loss))\n",
        "        img = deprocess_image(combination_image.numpy(), nrows=img_nrows, ncols=img_ncols)\n",
        "        fname = result_prefix + \"_at_iteration_%d.png\" % i\n",
        "        keras.preprocessing.image.save_img(fname, img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtsIv9qFJfGc"
      },
      "source": [
        "After 12 iterations, you get the following result:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTeBBZC2JfGd"
      },
      "source": [
        "display(Image(result_prefix + \"_at_iteration_12.png\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JaVkApXmvdp9"
      },
      "source": [
        "# finalize and exit access to data in drive\n",
        "drive.flush_and_unmount()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}